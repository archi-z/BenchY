##################################################################################
# Model-based Representations for Deep Deterministic Policy Gradient (MR-DDPG)
##################################################################################

agent_type: 'mrddpg'

device: {device}
seed: ${seed}
num_train_envs: ${env.num_train_envs}
max_episode_steps: ${env.max_episode_steps}
normalize_observation: true

zs_dim: 512
za_dim: 256
zsa_dim: 512
encoder_horizon: 5
encoder_num_blocks: 1
encoder_hidden_dim: 512
encoder_activ: 'ELU'
encoder_learning_rate: 1e-4
encoder_weight_decay: 1e-4

actor_num_blocks: 1
actor_hidden_dim: 128
actor_activ: 'ReLU'
actor_learning_rate: 1e-4
actor_weight_decay: 1e-4

critic_num_blocks: 2
critic_hidden_dim: 512
critic_activ: 'ELU'
critic_learning_rate: 1e-4
critic_weight_decay: 1e-2
critic_use_cdq: true

encoder_update_freq: 250
target_tau: 0.005
gamma: ${gamma}
n_step: ${n_step}

exp_noise_color: 0  # 0: gaussian, 1: pink, 2: ou
exp_noise_scheduler: 'linear'
exp_noise_decay_period: ${eval:'${num_interaction_steps} / 5'}
exp_noise_std_init: 0.1
exp_noise_std_final: 0.1

dyn_weight: 1
reward_weight: 0.1
done_weight: 0.1

num_bins: 65
lower: -10
upper: 10

mixed_precision: false
