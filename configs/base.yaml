##################################################################################
# Common
##################################################################################

project_name: 'BenchY'
group_name: ${agent.agent_type}_${env.env_name}_RR=${updates_per_interaction_step}
exp_name: seed=${seed}_${agent.agent_type}_${env.env_name}_AD=${agent.actor_num_blocks}_AW=${agent.actor_hidden_dim}_CD=${agent.critic_num_blocks}_CW=${agent.critic_hidden_dim}
seed: 0
server: 'local'

##################################################################################
# Training
##################################################################################

device: 'cuda' # [cuda, cpu]

# gamma value is set with a heuristic from TD-MPCv2
eff_episode_len: ${eval:'${env.max_episode_steps} / ${env.action_repeat}'}
gamma: ${eval:'max(min((${eff_episode_len} / 5 - 1) / (${eff_episode_len} / 5), 0.995), 0.95)'}
n_step: 1

num_train_envs: ${env.num_train_envs}
num_env_steps: ${env.num_env_steps}
action_repeat: ${env.action_repeat}

num_interaction_steps: ${eval:'${num_env_steps} / (${num_train_envs} * ${action_repeat})'}
updates_per_interaction_step: 2           # number of updates per interaction step.
evaluation_per_interaction_step: 25_000   # evaluation frequency per interaction step.
recording_per_interaction_step: ${num_interaction_steps}   # video recording frequency per interaction step.
logging_per_interaction_step: 5_000       # logging frequency per interaction step.
num_eval_episodes: 10
num_record_episodes: 1

defaults:
- _self_
- agent: ddpg
- buffer: numpy_uniform
- env: dmc_hard
